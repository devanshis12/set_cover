{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE FILE BEFORE SUBMITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input is a set of n elements and a collection of subsets of these elements. \n",
    "# The goal is to find the smallest number of subsets such that their union covers all elements in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\napproximation guarantees of O(log n)\\nOPT is size of the optimal solution\\nk is size of the greedy solution\\nneed to show: GREEDY <= OPT * log n\\n    1. at each step, we pick the set that covers the most uncovered elements => GREEDY covers at least as many as any OPT set would\\n        - let m be the size of the set we picked\\n        - m <= size of the set OPT picked\\n    2. GREEDY covers at least >= remaining elements / size of the set we picked\\n    3. using recursion, let r_i be the number of remaining elements after i iterations\\n        5. r_i <= r_{i-1} - r_{i-1}/m (r_i = 0 is the goal => all elements are covered)\\n        6. r_i <= n(1 - 1/m)^i\\n        7. n(1 - 1/m)^k < 1     (take log of both sides)\\n        8. k >= m*log(n)         \\n        9. k = O(m*log(n))\\n        10. k = O(OPT*log n)    (since m <= OPT)\\n    11. k = O(log n)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "approximation guarantees of O(log n)\n",
    "OPT is size of the optimal solution\n",
    "k is size of the greedy solution\n",
    "need to show: GREEDY <= OPT * log n\n",
    "    1. at each step, we pick the set that covers the most uncovered elements => GREEDY covers at least as many as any OPT set would\n",
    "        - let m be the size of the set we picked\n",
    "        - m <= size of the set OPT picked\n",
    "    2. GREEDY covers at least >= remaining elements / size of the set we picked\n",
    "    3. using recursion, let r_i be the number of remaining elements after i iterations\n",
    "        5. r_i <= r_{i-1} - r_{i-1}/m (r_i = 0 is the goal => all elements are covered)\n",
    "        6. r_i <= n(1 - 1/m)^i\n",
    "        7. n(1 - 1/m)^k < 1     (take log of both sides)\n",
    "        8. k >= m*log(n)         \n",
    "        9. k = O(m*log(n))\n",
    "        10. k = O(OPT*log n)    (since m <= OPT)\n",
    "    11. k = O(log n)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea 1: select the subset that covers the most uncovered elements i.e. when added to the cover, increases the number of covered elements the most\n",
    "\n",
    "def approx_msc(U, S):\n",
    "    '''\n",
    "    input: U = {x_1, x_2, ..., x_n}: set of n elements\n",
    "           S = {S_1, S_2, ..., S_m} where S_i is a subset of U: list of sets\n",
    "    output: C is a subset of S such that C covers all elements in U: list of sets\n",
    "    '''\n",
    "    C = []                # initialize the cover as empty\n",
    "    uncovered = set(U)    # all elements in U are initially uncovered\n",
    "    while uncovered:      # while there are still uncovered elements\n",
    "        best_subset = max(S, key=lambda s: len(uncovered & s))  # find the subset that covers the most uncovered elements\n",
    "        C.append(best_subset)     # add it to the cover\n",
    "        uncovered -= best_subset  # remove the covered elements from the uncovered set\n",
    "\n",
    "    # below is optional\n",
    "    def needs_pruning(s, C):\n",
    "        # check if the set s is necessary in the cover\n",
    "        # a set is necessary if removing it would leave some elements uncovered\n",
    "        remaining = set().union(*(c for c in C if c != s))\n",
    "        return s <= remaining  # if s is a subset of the remaining sets, it is not necessary\n",
    "    \n",
    "    # prune the cover to remove any redundant sets\n",
    "    pruned = []\n",
    "    for s in C:\n",
    "        temp_cover = pruned + [x for x in C if x != s]\n",
    "        if not needs_pruning(s, temp_cover):\n",
    "            pruned.append(s)\n",
    "    C = pruned  # update the cover with the pruned sets\n",
    "\n",
    "    return C               # return the cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    n, m = map(int, lines[0].split())\n",
    "    S = []\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        parts = list(map(int, line.split()))\n",
    "        S_i = set(parts[1:])\n",
    "        S.append(S_i)\n",
    "    U = set(range(1, n + 1))\n",
    "    return U, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: {1, 2, 3}\n",
      "S: [{3}, {1, 3}, {2, 3}]\n",
      "C: [{1, 3}, {2, 3}]\n"
     ]
    }
   ],
   "source": [
    "# test1.in\n",
    "filename = '../data/test1.in'\n",
    "U, S = read_input(filename)\n",
    "print('U:', U)\n",
    "print('S:', S)\n",
    "C = approx_msc(U, S)\n",
    "print('C:', C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: {1, 2, 3, 4, 5}\n",
      "S: [{5}, {1}, {4, 5}, {5}, {4}, {1, 2, 4}, {1, 2, 3}]\n",
      "C: [{1, 2, 4}, {5}, {1, 2, 3}]\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/test2.in'\n",
    "U, S = read_input(filename)\n",
    "print('U:', U)\n",
    "print('S:', S)\n",
    "C = approx_msc(U, S)\n",
    "print('C:', C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
      "S: [{1, 6, 7}, {8, 5}, {8, 4}, {3}, {8, 2}, {10, 5}, {1}, {9, 5, 6}, {7}, {3}]\n",
      "C: [{1, 6, 7}, {8, 4}, {3}, {8, 2}, {10, 5}, {9, 5, 6}]\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/test3.in'\n",
    "U, S = read_input(filename)\n",
    "print('U:', U)\n",
    "print('S:', S)\n",
    "C = approx_msc(U, S)\n",
    "print('C:', C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n",
      "S: [{1, 3, 9}, {5, 6}, {10, 6}, {8, 2, 4}, {5, 7}]\n",
      "C: [{1, 3, 9}, {8, 2, 4}, {10, 6}, {5, 7}]\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/test4.in'\n",
    "U, S = read_input(filename)\n",
    "print('U:', U)\n",
    "print('S:', S)\n",
    "C = approx_msc(U, S)\n",
    "print('C:', C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: {1, 2, 3, 4, 5, 6, 7}\n",
      "S: [{4}, {4}, {6, 7}, {5}, {1}, {1, 5}, {4}, {2, 5}, {1, 3}, {1}]\n",
      "C: [{6, 7}, {4}, {2, 5}, {1, 3}]\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/test5.in'\n",
    "U, S = read_input(filename)\n",
    "print('U:', U)\n",
    "print('S:', S)\n",
    "C = approx_msc(U, S)\n",
    "print('C:', C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comprehensive evaluation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    opt_val = int(lines[0].strip())\n",
    "    return opt_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_error(approx_val, opt_val):\n",
    "    return abs(approx_val - opt_val) / opt_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_measure(input, output):\n",
    "    U, S = read_input(input)\n",
    "    start = time.time()\n",
    "    C = approx_msc(U, S)\n",
    "    elapsed = time.time() - start\n",
    "    alg_val = len(C)\n",
    "    opt_val = read_output(output)\n",
    "    rel_err = rel_error(alg_val, opt_val)\n",
    "    return round(elapsed, 2), alg_val, round(rel_err, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset  Time (s)  size  RelErr\n",
      "0   test1       0.0     2     0.0\n",
      "1   test2       0.0     3     0.5\n",
      "2   test3       0.0     6     0.0\n",
      "3   test4       0.0     4     0.0\n",
      "4   test5       0.0     4     0.0\n"
     ]
    }
   ],
   "source": [
    "test_dataset = []\n",
    "for i in range(1, 6):\n",
    "    input = f'../data/test{i}.in'\n",
    "    output = f'../data/test{i}.out'\n",
    "    elapsed, alg_val, rel_err = run_and_measure(input, output)\n",
    "    data = os.path.splitext(os.path.basename(input))[0]\n",
    "    test_dataset.append((data, elapsed, alg_val, rel_err))\n",
    "\n",
    "test_df = pd.DataFrame(test_dataset, columns=['Dataset', 'Time (s)', 'size', 'RelErr'])\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Dataset  Time (s)  size  RelErr\n",
      "0    small1       0.0     5    0.00\n",
      "1    small2       0.0     4    0.33\n",
      "2    small3       0.0     6    0.20\n",
      "3    small4       0.0     5    0.25\n",
      "4    small5       0.0     6    0.20\n",
      "5    small6       0.0     4    0.33\n",
      "6    small7       0.0     4    0.33\n",
      "7    small8       0.0     3    0.50\n",
      "8    small9       0.0     4    0.33\n",
      "9   small10       0.0     3    0.50\n",
      "10  small11       0.0     5    0.25\n",
      "11  small12       0.0     4    0.33\n",
      "12  small13       0.0     3    0.50\n",
      "13  small14       0.0     3    0.50\n",
      "14  small15       0.0     3    0.50\n",
      "15  small16       0.0     3    0.50\n",
      "16  small17       0.0     3    0.50\n",
      "17  small18       0.0     3    0.50\n"
     ]
    }
   ],
   "source": [
    "small_dataset = []\n",
    "for i in range(1, 19):\n",
    "    input = f'../data/small{i}.in'\n",
    "    output = f'../data/small{i}.out'\n",
    "    elapsed, alg_val, rel_err = run_and_measure(input, output)\n",
    "    data = os.path.splitext(os.path.basename(input))[0]\n",
    "    small_dataset.append((data, elapsed, alg_val, rel_err))\n",
    "\n",
    "small_df = pd.DataFrame(small_dataset, columns=['Dataset', 'Time (s)', 'size', 'RelErr'])\n",
    "print(small_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Dataset  Time (s)  size  RelErr\n",
      "0    large1      0.35    50    0.00\n",
      "1    large2      0.00    20    0.05\n",
      "2    large3      0.00    17    0.13\n",
      "3    large4      0.14   152    0.67\n",
      "4    large5      0.00     8    0.33\n",
      "5    large6      0.01     7    0.17\n",
      "6    large7      0.34   172    0.81\n",
      "7    large8      0.00     6    0.20\n",
      "8    large9      0.00    16    0.14\n",
      "9   large10      0.28   318    0.44\n",
      "10  large11      0.06    56    0.40\n",
      "11  large12      0.00    18    0.20\n"
     ]
    }
   ],
   "source": [
    "large_dataset = []\n",
    "for i in range(1, 13):\n",
    "    input = f'../data/large{i}.in'\n",
    "    output = f'../data/large{i}.out'\n",
    "    elapsed, alg_val, rel_err = run_and_measure(input, output)\n",
    "    data = os.path.splitext(os.path.basename(input))[0]\n",
    "    large_dataset.append((data, elapsed, alg_val, rel_err))\n",
    "\n",
    "large_df = pd.DataFrame(large_dataset, columns=['Dataset', 'Time (s)', 'size', 'RelErr'])\n",
    "print(large_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Dataset  Time (s)  size  RelErr\n",
      "0     test1      0.00     2    0.00\n",
      "1     test2      0.00     3    0.50\n",
      "2     test3      0.00     6    0.00\n",
      "3     test4      0.00     4    0.00\n",
      "4     test5      0.00     4    0.00\n",
      "5    small1      0.00     5    0.00\n",
      "6    small2      0.00     4    0.33\n",
      "7    small3      0.00     6    0.20\n",
      "8    small4      0.00     5    0.25\n",
      "9    small5      0.00     6    0.20\n",
      "10   small6      0.00     4    0.33\n",
      "11   small7      0.00     4    0.33\n",
      "12   small8      0.00     3    0.50\n",
      "13   small9      0.00     4    0.33\n",
      "14  small10      0.00     3    0.50\n",
      "15  small11      0.00     5    0.25\n",
      "16  small12      0.00     4    0.33\n",
      "17  small13      0.00     3    0.50\n",
      "18  small14      0.00     3    0.50\n",
      "19  small15      0.00     3    0.50\n",
      "20  small16      0.00     3    0.50\n",
      "21  small17      0.00     3    0.50\n",
      "22  small18      0.00     3    0.50\n",
      "23   large1      0.35    50    0.00\n",
      "24   large2      0.00    20    0.05\n",
      "25   large3      0.00    17    0.13\n",
      "26   large4      0.14   152    0.67\n",
      "27   large5      0.00     8    0.33\n",
      "28   large6      0.01     7    0.17\n",
      "29   large7      0.34   172    0.81\n",
      "30   large8      0.00     6    0.20\n",
      "31   large9      0.00    16    0.14\n",
      "32  large10      0.28   318    0.44\n",
      "33  large11      0.06    56    0.40\n",
      "34  large12      0.00    18    0.20\n"
     ]
    }
   ],
   "source": [
    "comprehensive_df = pd.concat([test_df, small_df, large_df], ignore_index=True)\n",
    "print(comprehensive_df)\n",
    "comprehensive_df.to_csv('comprehensive_approx.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
