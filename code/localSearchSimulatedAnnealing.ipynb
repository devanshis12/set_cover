{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MjT6PqJ8Tvl6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'here are many variants of local search (LS) and you are free to select which one you\\nwant to implement. Please implement 2 types/variants of local search. They can be in different families\\nof LS such as Simulated Annealing vs Hill Climbing, or they can be in the same general family but\\nshould differ by the neighborhood they are using, or by the perturbation strategy, etc.\\n\\nHint: While local search does not guarantee the convergence of solutions, most of the time it should\\nconverge relatively quickly given a good search space. How do you formulate the search space such that\\nthe exploration is efficient and doesn’t get stuck? This can have a night-and-day difference in simulated\\nannealing or hill climbing algorithms.'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"here are many variants of local search (LS) and you are free to select which one you\n",
        "want to implement. Please implement 2 types/variants of local search. They can be in different families\n",
        "of LS such as Simulated Annealing vs Hill Climbing, or they can be in the same general family but\n",
        "should differ by the neighborhood they are using, or by the perturbation strategy, etc.\n",
        "\n",
        "Hint: While local search does not guarantee the convergence of solutions, most of the time it should\n",
        "converge relatively quickly given a good search space. How do you formulate the search space such that\n",
        "the exploration is efficient and doesn’t get stuck? This can have a night-and-day difference in simulated\n",
        "annealing or hill climbing algorithms.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_IOjRNRZiC-t"
      },
      "outputs": [],
      "source": [
        "# The input is a set of n elements and a collection of subsets of these elements.\n",
        "# The goal is to find the smallest number of subsets such that their union covers all elements in the set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Dq0ica1oiH9F"
      },
      "outputs": [],
      "source": [
        "# idea: Simulated Annealing\n",
        "# - start with approx algo solution that covers all elements\n",
        "# - iteratively explores neighboring solutions by adding, swapping, or removing subsets based on probability -- 33% each\n",
        "# - The cost function will minimize number of subsets (cost will be length of set of subsets)\n",
        "# - SA's temperature parameter starts at 200, uses cooling rate of 0.995 per iteration\n",
        "# - after 100 iterations, if no improvement, algorithm will return the set cover"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import argparse\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "import glob\n",
        "\n",
        "\n",
        "#parsing the input file\n",
        "def parse_instance(filepath):\n",
        "    with open(filepath, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    n, m = map(int, lines[0].split())\n",
        "    S = []\n",
        "    raw_indices = []\n",
        "    for i, line in enumerate(lines[1:], 1):\n",
        "        parts = list(map(int, line.split()))\n",
        "        S_i = set(parts[1:])\n",
        "        S.append(S_i)\n",
        "        raw_indices.append(i)\n",
        "    U = set(range(1, n + 1))\n",
        "    return U, S, raw_indices\n",
        "\n",
        "#approx algo to initialize guess\n",
        "def greedy_approx(U, S, raw_indices):\n",
        "    cover_indices = []\n",
        "    uncovered = set(U)\n",
        "    S_copy = list(zip(S, range(len(S)), raw_indices))\n",
        "    while uncovered:\n",
        "        best_idx = max(range(len(S_copy)), key=lambda i: len(uncovered & S_copy[i][0]))\n",
        "        best_set, idx, raw_idx = S_copy[best_idx]\n",
        "        cover_indices.append(idx)\n",
        "        uncovered -= best_set\n",
        "        S_copy.pop(best_idx)\n",
        "        if not uncovered:\n",
        "            break\n",
        "    original_indices = [raw_indices[i] for i in cover_indices]\n",
        "    return cover_indices, original_indices\n",
        "\n",
        "#Return the set of elements covered by the given solution indices\n",
        "def get_coverage(solution_indices, S):\n",
        "    covered = set()\n",
        "    for i in solution_indices:\n",
        "        covered.update(S[i])\n",
        "    return covered\n",
        "\n",
        "#checks if the solution currently is valid\n",
        "def is_valid_solution(solution_indices, S, U):\n",
        "    return get_coverage(solution_indices, S) == U\n",
        "\n",
        "#implementing pruning to get rid of redundancies in the set\n",
        "def prune_solution(solution_indices, S, U):\n",
        "    res = solution_indices.copy()\n",
        "    i = 0\n",
        "    while i < len(res):\n",
        "        candidate = res[:i] + res[i+1:]\n",
        "        if is_valid_solution(candidate, S, U):\n",
        "            res = candidate\n",
        "            i = 0\n",
        "        else:\n",
        "            i += 1\n",
        "    return res\n",
        "\n",
        "#Simulated annealing main code\n",
        "\"\"\" Simulated Annealing\n",
        "- Uses Approximation Algorithm as the initial solution\n",
        "\n",
        "- Implements Simulated Annealing with:\n",
        "    - A time cutoff (in seconds)\n",
        "    - A no-improvement cutoff along with time cutoff\n",
        "    - A probabilistic acceptance of worse moves based on a temperature schedule\n",
        "    - add, swap, and remove possibilities at each iteration\n",
        "    - run for max of 10 minutes per .in file\n",
        "    - use \"python3 simulatedannealing.py -inst ../data -alg LS1 -time 600 -seed 45\" to run\n",
        "\"\"\"\n",
        "def simulated_annealing(U, S, raw_indices, cutoff_time, seed=1, threshold=100, initial_solution=None):\n",
        "    random.seed(seed)\n",
        "    start_time = time.time()\n",
        "\n",
        "    if initial_solution is None:\n",
        "        solution_indices, n = greedy_approx(U, S, raw_indices)\n",
        "    else:\n",
        "        solution_indices = initial_solution.copy()\n",
        "    solution_indices = prune_solution(solution_indices, S, U)\n",
        "    trace = [(0.0, len(solution_indices))]\n",
        "    temp = 200\n",
        "    final_temp = 2\n",
        "    alpha = 0.995\n",
        "    base_iterations = max(10, len(S) // 5)\n",
        "    best_solution = solution_indices.copy()\n",
        "    best_quality = len(best_solution)\n",
        "    current_solution = solution_indices.copy()\n",
        "    current_quality = len(current_solution)\n",
        "    s = 0\n",
        "    c = 0\n",
        "    while temp > final_temp and (time.time() - start_time < cutoff_time) and (s < threshold):\n",
        "        improved = False\n",
        "        if s > 50:\n",
        "            iters = base_iterations * 2 #try and do more work if approaching 100 same results\n",
        "        else:\n",
        "            iters = base_iterations\n",
        "        for i in range(iters):\n",
        "            if time.time() - start_time >= cutoff_time:\n",
        "                break\n",
        "            c += 1\n",
        "            if c % 100 == 0:\n",
        "                print(f\"Iteration {c}: Temp={temp:.2f}, Current Quality={current_quality}, \"\n",
        "                      f\"Best Quality={best_quality}, stagnation={s}\")\n",
        "            neighbors = []\n",
        "            for i in range(len(current_solution)):\n",
        "                candidate = current_solution[:i] + current_solution[i+1:]\n",
        "                if is_valid_solution(candidate, S, U):\n",
        "                    candidate = prune_solution(candidate, S, U)\n",
        "                    neighbors.append(candidate)\n",
        "            curr = set(range(len(S)))\n",
        "            not_in_solution = list(curr - set(current_solution))\n",
        "            #add \n",
        "            if not_in_solution:\n",
        "                candidate = current_solution.copy()\n",
        "                candidate.append(random.choice(not_in_solution))\n",
        "                candidate = prune_solution(candidate, S, U)\n",
        "                if is_valid_solution(candidate, S, U):\n",
        "                    neighbors.append(candidate)\n",
        "            #swap\n",
        "            if current_solution and not_in_solution:\n",
        "                candidate = current_solution.copy()\n",
        "                iswap = random.randint(0, len(candidate) - 1)\n",
        "                candidate[iswap] = random.choice(not_in_solution)\n",
        "                candidate = prune_solution(candidate, S, U)\n",
        "                if is_valid_solution(candidate, S, U):\n",
        "                    neighbors.append(candidate)\n",
        "            if len(current_solution) > 1:\n",
        "                candidate = current_solution.copy()\n",
        "                removal_index = random.choice(range(len(current_solution)))\n",
        "                candidate.pop(removal_index)\n",
        "                if is_valid_solution(candidate, S, U):\n",
        "                    candidate = prune_solution(candidate, S, U)\n",
        "                    neighbors.append(candidate)\n",
        "            if not neighbors:\n",
        "                continue\n",
        "            for q in range(1):\n",
        "                new_solution = random.choice(neighbors)\n",
        "                new_quality = len(new_solution)\n",
        "                delta = new_quality - current_quality\n",
        "                if delta < 0 or random.random() < math.exp(-delta / temp):\n",
        "                    current_solution = new_solution.copy()\n",
        "                    current_quality = new_quality\n",
        "                    if current_quality < best_quality:\n",
        "                        best_solution = current_solution.copy()\n",
        "                        best_quality = current_quality\n",
        "                        trace.append((time.time() - start_time, best_quality))\n",
        "                        improved = True\n",
        "        if not improved:\n",
        "            s += 1\n",
        "        else:\n",
        "            s = 0\n",
        "        temp *= alpha\n",
        "    original_indices = [raw_indices[i] for i in best_solution]\n",
        "    elapsed = time.time() - start_time\n",
        "    return best_solution, original_indices, trace, elapsed\n",
        "\n",
        "#writing .sol and .trace files\n",
        "def write_output(instance_path, method, cutoff, original_indices, seed=None, trace=None):\n",
        "    instance_name = os.path.splitext(os.path.basename(instance_path))[0]\n",
        "    output_dir = \"../output\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    if method in [\"LS1\"]:\n",
        "        base_name = f\"{instance_name}_{method}_{cutoff}_{seed}\"\n",
        "    solution_path = os.path.join(output_dir, f\"{base_name}.sol\")\n",
        "    with open(solution_path, 'w') as f:\n",
        "        f.write(f\"{len(original_indices)}\\n\")\n",
        "        f.write(\" \".join(map(str, original_indices)) + \"\\n\")\n",
        "    if trace and method in [\"LS1\"]:\n",
        "        trace_path = os.path.join(output_dir, f\"{base_name}.trace\")\n",
        "        with open(trace_path, 'w') as f:\n",
        "            for timestamp, quality in trace:\n",
        "                f.write(f\"{timestamp:.2f} {quality}\\n\")\n",
        "\n",
        "#main code to run the simulated annealing helper function\n",
        "def process_file(file_path, algorithm, cutoff_time, seed):\n",
        "    U, S, raw_indices = parse_instance(file_path)\n",
        "    if algorithm == \"LS1\":\n",
        "        initial_solution, x = greedy_approx(U, S, raw_indices)\n",
        "        initial_solution = prune_solution(initial_solution, S, U)\n",
        "        best_solution, original_indices, trace, nxt = simulated_annealing(\n",
        "            U, S, raw_indices, cutoff_time, seed=seed, initial_solution=initial_solution)\n",
        "        write_output(file_path, algorithm, cutoff_time, original_indices, seed, trace)\n",
        "\n",
        "#main function to establish terminal arguments and combining .in files\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Minimum Set Cover Solver\")\n",
        "    parser.add_argument('-inst', required=True)\n",
        "    parser.add_argument('-alg', choices=['LS1'], required=True)\n",
        "    parser.add_argument('-time', type=int, required=True)\n",
        "    parser.add_argument('-seed', type=int, default=42)\n",
        "    args = parser.parse_args()\n",
        "    if os.path.isfile(args.inst):\n",
        "        process_file(args.inst, args.alg, args.time, args.seed)\n",
        "    elif os.path.isdir(args.inst) or args.inst == 'data':\n",
        "        data_dir = args.inst if args.inst.endswith(os.sep) else args.inst + os.sep\n",
        "        in_files = sorted(glob.glob(f\"{data_dir}*.in\"))\n",
        "        for file_path in in_files:\n",
        "            process_file(file_path, args.alg, args.time, args.seed)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def read_sol(filename):\n",
        "    \"\"\"Reads a solution (.sol) file and returns the solution size (the first line).\"\"\"\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    sol_size = int(lines[0].strip())\n",
        "    return sol_size\n",
        "\n",
        "def read_trace(filename):\n",
        "    last_time = None\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = [line.strip() for line in f if line.strip()]\n",
        "    if lines:\n",
        "        last_line = lines[-1]\n",
        "        parts = last_line.split()\n",
        "        last_time = float(parts[0])\n",
        "    return last_time\n",
        "\n",
        "def read_output(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    opt_val = int(lines[0].strip())\n",
        "    return opt_val\n",
        "\n",
        "def rel_error(approx_val, opt_val):\n",
        "    return abs(approx_val - opt_val) / opt_val\n",
        "\n",
        "def process_dataset(dataset_prefix, index_range, sol_dir, data_dir, method, cutoff, seed):\n",
        "    records = []\n",
        "    for i in index_range:\n",
        "        input_filename = os.path.join(data_dir, f\"{dataset_prefix}{i}.in\")\n",
        "        out_filename = os.path.join(data_dir, f\"{dataset_prefix}{i}.out\")\n",
        "        sol_filename = os.path.join(sol_dir, f\"{dataset_prefix}{i}_{method}_{cutoff}_{seed}.sol\")\n",
        "        trace_filename = os.path.join(sol_dir, f\"{dataset_prefix}{i}_{method}_{cutoff}_{seed}.trace\")\n",
        "        \n",
        "        alg_size = read_sol(sol_filename)\n",
        "        opt_size = read_output(out_filename)\n",
        "        error = rel_error(alg_size, opt_size)\n",
        "        time_val = None\n",
        "        if os.path.exists(trace_filename):\n",
        "            time_val = read_trace(trace_filename)\n",
        "        dataset_name = f\"{dataset_prefix}{i}\"\n",
        "        records.append((dataset_name, time_val, alg_size, round(error, 2)))\n",
        "\n",
        "    df = pd.DataFrame(records, columns=['Dataset', 'Time (s)', 'size', 'RelErr'])\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Small Datasets DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>size</th>\n",
              "      <th>RelErr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>small1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>small2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>small3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>small4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>small5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>small6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>small7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>small8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>small9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>small10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>small11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>small12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>small13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>small14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>small15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>small16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>small17</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>small18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Dataset  Time (s)  size  RelErr\n",
              "0    small1      0.00     5     0.0\n",
              "1    small2      0.00     3     0.0\n",
              "2    small3      0.00     5     0.0\n",
              "3    small4      0.00     4     0.0\n",
              "4    small5      0.00     5     0.0\n",
              "5    small6      0.00     3     0.0\n",
              "6    small7      0.00     3     0.0\n",
              "7    small8      0.00     2     0.0\n",
              "8    small9      0.00     3     0.0\n",
              "9   small10      0.00     2     0.0\n",
              "10  small11      0.00     4     0.0\n",
              "11  small12      0.00     3     0.0\n",
              "12  small13      0.00     2     0.0\n",
              "13  small14      0.00     2     0.0\n",
              "14  small15      0.00     2     0.0\n",
              "15  small16      0.00     2     0.0\n",
              "16  small17      0.01     2     0.0\n",
              "17  small18      0.00     2     0.0"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sol_dir = \"../output\"\n",
        "data_dir = \"../data\"\n",
        "method = \"LS1\"\n",
        "cutoff = 600\n",
        "seed = 45\n",
        "\n",
        "small_df = process_dataset(\"small\", range(1, 19), sol_dir, data_dir, method, cutoff, seed)\n",
        "print(\"Small Datasets DataFrame:\")\n",
        "small_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Large Datasets DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>size</th>\n",
              "      <th>RelErr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>large1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>50</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>large2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>20</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>large3</td>\n",
              "      <td>0.16</td>\n",
              "      <td>16</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>large4</td>\n",
              "      <td>172.85</td>\n",
              "      <td>147</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>large5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>large6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>large7</td>\n",
              "      <td>258.97</td>\n",
              "      <td>168</td>\n",
              "      <td>0.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>large8</td>\n",
              "      <td>0.09</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>large9</td>\n",
              "      <td>2.95</td>\n",
              "      <td>15</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>large10</td>\n",
              "      <td>580.77</td>\n",
              "      <td>304</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>large11</td>\n",
              "      <td>8.42</td>\n",
              "      <td>55</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>large12</td>\n",
              "      <td>0.66</td>\n",
              "      <td>17</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Dataset  Time (s)  size  RelErr\n",
              "0    large1      0.00    50    0.00\n",
              "1    large2      0.00    20    0.05\n",
              "2    large3      0.16    16    0.07\n",
              "3    large4    172.85   147    0.62\n",
              "4    large5      0.00     7    0.17\n",
              "5    large6      0.00     7    0.17\n",
              "6    large7    258.97   168    0.77\n",
              "7    large8      0.09     5    0.00\n",
              "8    large9      2.95    15    0.07\n",
              "9   large10    580.77   304    0.38\n",
              "10  large11      8.42    55    0.38\n",
              "11  large12      0.66    17    0.13"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "large_df = process_dataset(\"large\", range(1, 13), sol_dir, data_dir, method, cutoff, seed)\n",
        "print(\"Large Datasets DataFrame:\")\n",
        "large_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Datasets DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>size</th>\n",
              "      <th>RelErr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Dataset  Time (s)  size  RelErr\n",
              "0   test1       0.0     2     0.0\n",
              "1   test2       0.0     2     0.0\n",
              "2   test3       0.0     6     0.0\n",
              "3   test4       0.0     4     0.0\n",
              "4   test5       0.0     4     0.0"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = process_dataset(\"test\", range(1, 6), sol_dir, data_dir, method, cutoff, seed)\n",
        "print(\"Test Datasets DataFrame:\")\n",
        "test_df\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
